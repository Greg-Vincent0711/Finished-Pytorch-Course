{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n","metadata":{"id":"GuQzytIXtOPv","execution":{"iopub.status.busy":"2024-02-14T02:07:13.229073Z","iopub.status.idle":"2024-02-14T02:07:13.229454Z","shell.execute_reply.started":"2024-02-14T02:07:13.229281Z","shell.execute_reply":"2024-02-14T02:07:13.229296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting up training data\ntrain_data = datasets.FashionMNIST(\n    root=\"data\", # where data is being downloaded\n    train=True, # get training split\n    download=True,\n    # images need to be tensors to work with a model\n    transform=ToTensor(),\n    # don't transform labels\n    target_transform=None\n)\n\n# setting up testing data\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False, # get testing split\n    download=True,\n    transform=ToTensor(),\n    target_transform=None\n)\n\n","metadata":{"id":"WE-FyPbvwOX4","outputId":"0040f8ac-93ce-464f-871a-303326556c75","execution":{"iopub.status.busy":"2024-02-14T02:07:13.230860Z","iopub.status.idle":"2024-02-14T02:07:13.231554Z","shell.execute_reply.started":"2024-02-14T02:07:13.231368Z","shell.execute_reply":"2024-02-14T02:07:13.231385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_data.classes\ntest_classes = test_data.classes","metadata":{"id":"tw7_hM0i2Soj","execution":{"iopub.status.busy":"2024-02-14T02:07:13.232792Z","iopub.status.idle":"2024-02-14T02:07:13.233121Z","shell.execute_reply.started":"2024-02-14T02:07:13.232954Z","shell.execute_reply":"2024-02-14T02:07:13.232967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image, label = train_data[0]\n# # plt expects height and width, no color channel\n# plt.imshow(image.squeeze())\n# plt.title(train_classes[label])","metadata":{"id":"I29aP8cnzRia","execution":{"iopub.status.busy":"2024-02-14T02:07:13.234085Z","iopub.status.idle":"2024-02-14T02:07:13.234425Z","shell.execute_reply.started":"2024-02-14T02:07:13.234262Z","shell.execute_reply":"2024-02-14T02:07:13.234276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(image.squeeze(), cmap=\"gray\")\n# plt.title(train_classes[label])\n# plt.axis(False)","metadata":{"id":"7udPXHDv2x08","execution":{"iopub.status.busy":"2024-02-14T02:07:13.235915Z","iopub.status.idle":"2024-02-14T02:07:13.236476Z","shell.execute_reply.started":"2024-02-14T02:07:13.236132Z","shell.execute_reply":"2024-02-14T02:07:13.236150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # just getting an idea of what the data looks like\n# fig = plt.figure(figsize=(9, 9))\n# rows, cols = 4,4\n# for i in range(1, rows * cols+1):\n#   random_index = torch.randint(0, len(train_data), size=[1]).item()\n#   image, label = train_data[random_index]\n#   fig.add_subplot(rows, cols, i)\n#   plt.imshow(image.squeeze(), cmap=\"gray\")\n#   plt.title(train_classes[label])\n","metadata":{"id":"tJH6AqRM3DuX","execution":{"iopub.status.busy":"2024-02-14T02:07:13.237814Z","iopub.status.idle":"2024-02-14T02:07:13.238286Z","shell.execute_reply.started":"2024-02-14T02:07:13.238035Z","shell.execute_reply":"2024-02-14T02:07:13.238052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing a dataloader\n# dataset -> dataloader(turns data into a python iterable )\nfrom torch.utils.data import DataLoader\nBATCH_SIZE = 32\n# shuffle training data so model doesn't learn img order\ndataLoader_Train = DataLoader(train_data, BATCH_SIZE, True)\n# shuffle doesn't matter for testing\ndataLoader_Test = DataLoader(test_data, BATCH_SIZE, False)","metadata":{"id":"9-T0RQqX4CyG","execution":{"iopub.status.busy":"2024-02-14T02:07:13.239785Z","iopub.status.idle":"2024-02-14T02:07:13.240249Z","shell.execute_reply.started":"2024-02-14T02:07:13.239994Z","shell.execute_reply":"2024-02-14T02:07:13.240012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # interacting with a dataloader\n# train_features_batch, train_labels_batch = next(iter(dataLoader_Train))\n# plt.imshow(train_features_batch[0].squeeze(), cmap=\"gray\")\n# plt.axis(False)\n# plt.title(train_classes[0])\n","metadata":{"id":"vixonW-89TkG","execution":{"iopub.status.busy":"2024-02-14T02:07:13.242020Z","iopub.status.idle":"2024-02-14T02:07:13.242536Z","shell.execute_reply.started":"2024-02-14T02:07:13.242264Z","shell.execute_reply":"2024-02-14T02:07:13.242283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FashionMNISTModelV0(nn.Module):\n  def __init__(self, input_shape:int,\n               hidden_units: int,\n               output_shape: int):\n    super().__init__()\n    self.layer_stack = nn.Sequential(\n        # reduce dims of input\n        nn.Flatten(),\n        nn.Linear(in_features=input_shape,\n                  out_features=hidden_units),\n        nn.Linear(in_features=hidden_units,\n                  out_features=output_shape))\n  def forward(self, input):\n    return self.layer_stack(input)\n","metadata":{"id":"kgAmA9oUM07Z","execution":{"iopub.status.busy":"2024-02-14T02:07:13.244150Z","iopub.status.idle":"2024-02-14T02:07:13.244536Z","shell.execute_reply.started":"2024-02-14T02:07:13.244366Z","shell.execute_reply":"2024-02-14T02:07:13.244381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\n\nmodel_0 = FashionMNISTModelV0(\n    # refers to shape of input data\n    input_shape=28*28,\n    hidden_units=10,\n    output_shape=len(class_names)\n).to(\"cpu\")","metadata":{"id":"6Cco7bxFM4BG","execution":{"iopub.status.busy":"2024-02-14T02:07:13.245675Z","iopub.status.idle":"2024-02-14T02:07:13.245989Z","shell.execute_reply.started":"2024-02-14T02:07:13.245830Z","shell.execute_reply":"2024-02-14T02:07:13.245843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculateAccuracy(y_true, y_pred):\n  correct = torch.eq(y_true, y_pred).sum().item()\n  return (correct / len(y_pred)) * 100","metadata":{"id":"CnG-mpu_aWpi","execution":{"iopub.status.busy":"2024-02-14T02:07:13.247428Z","iopub.status.idle":"2024-02-14T02:07:13.247805Z","shell.execute_reply.started":"2024-02-14T02:07:13.247602Z","shell.execute_reply":"2024-02-14T02:07:13.247632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting up a loss, optimizer and evaluation metrics\n\n# we're using multi-class data, so loss fn is CrossEntropy\n# optimizer is still SGD\nloss = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model_0.parameters(), lr=0.1)","metadata":{"id":"wJHGvcOZYE6P","execution":{"iopub.status.busy":"2024-02-14T02:07:13.249796Z","iopub.status.idle":"2024-02-14T02:07:13.250195Z","shell.execute_reply.started":"2024-02-14T02:07:13.249976Z","shell.execute_reply":"2024-02-14T02:07:13.249999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fn to track model speed\nfrom timeit import default_timer as timer\ndef print_training_time(startTime:float,\n                        endTime:float,\n                        device:torch.device = None):\n  runTime = endTime - startTime\n  print(f\"Training time for {device}:{runTime:.3f} seconds \")\n  return runTime\n","metadata":{"id":"mgpCJw6BapXZ","execution":{"iopub.status.busy":"2024-02-14T02:07:13.251634Z","iopub.status.idle":"2024-02-14T02:07:13.252099Z","shell.execute_reply.started":"2024-02-14T02:07:13.251862Z","shell.execute_reply":"2024-02-14T02:07:13.251880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training/testing model\n# for now, I'm writing both loops out to practice, but will functionize\ntorch.manual_seed(42)\n# start timer on run\ncpuStartTime = timer()\n# lower epochs = faster training time\nepochs = 3\nfor epoch in range((epochs)):\n  print(f\"Epoch # {epoch}\")\n  train_loss = 0\n  # loop through training batches\n  for batch, (train_image, label) in enumerate(dataLoader_Train):\n    model_0.train()\n    # create training predictions\n    image_training_preds = model_0(train_image)\n    # calculate loss and accuracy\n    lossamnt = loss(image_training_preds, label)\n    train_loss += lossamnt\n    # zero optimizer, backprop, update weights with optimizer step\n    optimizer.zero_grad()\n    lossamnt.backward()\n    optimizer.step()\n\n  # avg out training loss over all\n  train_loss /= len(dataLoader_Train)\n\n  test_loss, test_acc = 0,0\n  model_0.eval()\n  # no gradient tracking for a performance boost\n  with torch.inference_mode():\n    for test_image, label in dataLoader_Test:\n        image_testing_preds = model_0(test_image)\n        test_loss += loss(image_testing_preds, label)\n        # use argmax because chosen pred is based on max of probabilites\n        # passing that in over logits. dim=1 refers to column values in a row\n        test_acc += calculateAccuracy(label, image_testing_preds.argmax(dim=1))\n    # avg test loss and acc per batch\n    test_loss /= len(dataLoader_Test)\n    test_acc /= len(dataLoader_Test)\n  print(f\"\\n Train Loss {train_loss:.4f} | Test Loss: {test_loss:4f}, Test Acc: {test_acc:4f}\")\n\n# find training time\ncpuEndTime = timer()\ntrainTime_model_0 = print_training_time(cpuStartTime,\n                                        cpuEndTime,\n                                        str(next(model_0.parameters()).device))","metadata":{"id":"dnMQnYQ5fMWn","outputId":"4396a56e-4354-4556-fd90-4eae577bf322","execution":{"iopub.status.busy":"2024-02-14T02:07:13.253455Z","iopub.status.idle":"2024-02-14T02:07:13.253855Z","shell.execute_reply.started":"2024-02-14T02:07:13.253639Z","shell.execute_reply":"2024-02-14T02:07:13.253654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functionalizing testing loop\ntorch.manual_seed(42)\ndef eval_model(model: torch.nn.Module,\n               data_loader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               accuracy_fn,\n               device: torch.device = None):\n  loss, acc = 0,0\n  model.eval()\n  with torch.inference_mode():\n    for image, label in data_loader:\n      image,label = image.to(device),label.to(device)\n      model_preds = model(image)\n      # accumulating loss/acc values per batch\n      loss += loss_fn(model_preds, label)\n      acc += accuracy_fn(label, model_preds.argmax(dim=1))\n    # find avg loss/acc per batch\n    loss /= len(data_loader)\n    acc /= len(data_loader)\n    return {\n        \"model_name\": model.__class__.__name__,\n        \"model_test_loss\": loss.item(),\n        \"model_test_acc\": acc\n        }\n\nmodel_0_results = eval_model(model_0,\n                             dataLoader_Test,\n                             loss,\n                             calculateAccuracy)\nmodel_0_results","metadata":{"id":"VAXTEtH6gWyK","outputId":"a0c4a7c2-35b7-4afa-f2c4-804613345fd3","execution":{"iopub.status.busy":"2024-02-14T02:07:13.257918Z","iopub.status.idle":"2024-02-14T02:07:13.258612Z","shell.execute_reply.started":"2024-02-14T02:07:13.258418Z","shell.execute_reply":"2024-02-14T02:07:13.258435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# designing a device agnostic model with non-linearity\nclass FashionMNISTModelV1(nn.Module):\n  def __init__(self, input_shape:int,\n               hidden_units: int,\n               output_shape: int):\n    super().__init__()\n    self.layer_stack = nn.Sequential(\n        # reduce input to a single vector\n        nn.Flatten(),\n        nn.Linear(in_features=input_shape,\n                  out_features=hidden_units),\n        nn.ReLU(),\n        nn.Linear(in_features=hidden_units,\n                  out_features=output_shape),\n        nn.ReLU()\n        )\n  def forward(self, input):\n    return self.layer_stack(input)","metadata":{"id":"7lk3HIqFg4T9","execution":{"iopub.status.busy":"2024-02-14T02:07:13.260431Z","iopub.status.idle":"2024-02-14T02:07:13.260799Z","shell.execute_reply.started":"2024-02-14T02:07:13.260620Z","shell.execute_reply":"2024-02-14T02:07:13.260635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model is made with random numbers\ntorch.manual_seed(42)\nmodel_1 = FashionMNISTModelV1(input_shape=784,\n                              hidden_units=10,\n                              output_shape=len(test_classes)).to(device)\nnext(model_1.parameters()).device\n","metadata":{"id":"dJzVxVzH5YGz","outputId":"c800186a-5cdb-4cb3-c7a5-34bff21f5a0a","execution":{"iopub.status.busy":"2024-02-14T02:07:13.261940Z","iopub.status.idle":"2024-02-14T02:07:13.262277Z","shell.execute_reply.started":"2024-02-14T02:07:13.262090Z","shell.execute_reply":"2024-02-14T02:07:13.262102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1Loss = nn.CrossEntropyLoss()\nm1Optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)\n\n# functionizing training loop\n\ndef train_model(model:torch.nn.Module,\n               data_loader: torch.utils.data.DataLoader,\n               loss_fn:torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               accuracy_fn,\n               device: torch.device = device):\n  train_loss, train_acc = 0,0\n  model.train()\n  for batch, (train_image, label) in enumerate(data_loader):\n    train_image, label = train_image.to(device), label.to(device)\n    # create training predictions\n    image_training_preds = model(train_image)\n    # calculate loss and accuracy\n    loss = loss_fn(image_training_preds, label)\n    train_loss += loss\n    train_acc += accuracy_fn(label, image_training_preds.argmax(dim=1))\n    # zero optimizer, backprop, update weights with optimizer step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n  # avg out training loss over all\n  train_loss /= len(data_loader)\n  train_acc /= len(data_loader)\n  return {\n    \"model_name\": model.__class__.__name__,\n    \"train_loss\": train_loss,\n    \"train_acc\": train_acc\n  }","metadata":{"id":"lftDSZ_757R_","execution":{"iopub.status.busy":"2024-02-14T02:07:13.263396Z","iopub.status.idle":"2024-02-14T02:07:13.263748Z","shell.execute_reply.started":"2024-02-14T02:07:13.263575Z","shell.execute_reply":"2024-02-14T02:07:13.263589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from timeit import default_timer as timer\ngpuTimeStart = timer()\nepochs = 3\nfor epoch in range((epochs)):\n  train_model(model_1,\n              dataLoader_Train,\n              m1Loss,\n              m1Optimizer,\n              calculateAccuracy,\n              device)\n  eval_model(model_1,\n             dataLoader_Test,\n             m1Loss,\n             calculateAccuracy,\n             device)\ngpuTimeEnd = timer()\ngpuTrainTime = print_training_time(gpuTimeStart,\n                        gpuTimeEnd,\n                        str(next(model_1.parameters()).device))\n\n","metadata":{"id":"b__74RoGOIcG","outputId":"b1341f53-f30f-4047-d573-dc02a8745c9e","execution":{"iopub.status.busy":"2024-02-14T02:07:13.264905Z","iopub.status.idle":"2024-02-14T02:07:13.265249Z","shell.execute_reply.started":"2024-02-14T02:07:13.265059Z","shell.execute_reply":"2024-02-14T02:07:13.265072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1_results = eval_model(model_1,\n             dataLoader_Test,\n             m1Loss,\n             calculateAccuracy,\n             device)\n# a non CNN model in the gpu is much slower\nmodel_0_results, model_1_results","metadata":{"id":"j_GDoi4jYFvj","outputId":"e4337bfd-593f-4362-8a98-0e38186a1da2","execution":{"iopub.status.busy":"2024-02-14T02:07:13.266669Z","iopub.status.idle":"2024-02-14T02:07:13.266976Z","shell.execute_reply.started":"2024-02-14T02:07:13.266825Z","shell.execute_reply":"2024-02-14T02:07:13.266838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN section starts below","metadata":{"id":"CrdghoJtYwQi","execution":{"iopub.status.busy":"2024-02-14T02:07:13.268212Z","iopub.status.idle":"2024-02-14T02:07:13.268730Z","shell.execute_reply.started":"2024-02-14T02:07:13.268385Z","shell.execute_reply":"2024-02-14T02:07:13.268398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# creating a CNN - replicates Tiny VGG\nclass FashionMNISTModelV2(nn.Module):\n  def __init__(self,input_shape:int,\n               hidden_units:int,\n               output_shape:int):\n    super().__init__()\n    # one block has conv layer -> ReLU -> pooling\n    self.block_1 = nn.Sequential(\n        nn.Conv2d(in_channels=input_shape,\n                  out_channels=hidden_units,\n                  # size of the filter\n                  kernel_size=3,\n                  # how much ground the filter covers at a time\n                  stride=1,\n                  # how much space to put around an image\n                  padding=1),\n        nn.ReLU(),\n        nn.Conv2d(in_channels=hidden_units,\n                  out_channels=hidden_units,\n                  kernel_size=3,\n                  stride=1,\n                  padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2)\n    )\n    self.block_2 = nn.Sequential(\n        nn.Conv2d(in_channels=hidden_units,\n                  out_channels=hidden_units,\n                  kernel_size=3,\n                  stride=1,\n                  padding=1),\n        nn.ReLU(),\n        nn.Conv2d(in_channels=hidden_units,\n                  out_channels=hidden_units,\n                  kernel_size=3,\n                  stride=1,\n                  padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2)\n    )\n    self.classifierLayer = nn.Sequential(\n        # output of two blocks is multidimensional tensor\n        # needs to be a single dimension tensor\n        # for a fully connected layer\n        nn.Flatten(),\n        # we need to mulitply the linear layers' input dims\n        # by the dims of the output from the 2nd conv block\n        # hence the 7*7. this avoids a shape runtime error\n        nn.Linear(in_features=hidden_units*7*7,\n                  out_features=len(class_names))\n        )\n  def forward(self, input):\n    input = self.block_1(input)\n    input = self.block_2(input)\n    return self.classifierLayer(input)\n","metadata":{"id":"9FjXzo_lmJnM","execution":{"iopub.status.busy":"2024-02-14T02:07:13.270156Z","iopub.status.idle":"2024-02-14T02:07:13.270534Z","shell.execute_reply.started":"2024-02-14T02:07:13.270366Z","shell.execute_reply":"2024-02-14T02:07:13.270381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\ncnnModel = FashionMNISTModelV2(\n    # only one color channel since imgs are black and white\n    input_shape=1,\n    hidden_units=10,\n    output_shape=len(class_names)\n).to(device)","metadata":{"id":"Dd9e-FaYmPlL","execution":{"iopub.status.busy":"2024-02-14T02:07:13.271892Z","iopub.status.idle":"2024-02-14T02:07:13.272245Z","shell.execute_reply.started":"2024-02-14T02:07:13.272060Z","shell.execute_reply":"2024-02-14T02:07:13.272073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnnLoss = nn.CrossEntropyLoss()\ncnnOptim = torch.optim.SGD(params=cnnModel.parameters(), lr=0.1)\nfrom timeit import default_timer as timer\ncnnModelStart = timer()\nepochs = 3\nfor epoch in range(epochs):\n    train_model(cnnModel,\n                dataLoader_Train,\n                cnnLoss,\n                cnnOptim,\n                calculateAccuracy,\n                device=device)\n    eval_model(cnnModel,\n               dataLoader_Test,\n               cnnLoss,\n               calculateAccuracy,\n               device=device\n               )\ncnnModelEnd = timer()\ncnnModelTrainTime = print_training_time(cnnModelStart,\n                        cnnModelEnd,\n                        str(next(cnnModel.parameters()).device))\ncnnModel_results = eval_model(cnnModel,\n               dataLoader_Test,\n               cnnLoss,\n               calculateAccuracy,\n               device=device\n               )\n","metadata":{"id":"7nRkltV1mQU6","outputId":"6dca12de-ba2a-46d7-de15-ce47c6557872","execution":{"iopub.status.busy":"2024-02-14T02:07:13.273633Z","iopub.status.idle":"2024-02-14T02:07:13.274119Z","shell.execute_reply.started":"2024-02-14T02:07:13.273879Z","shell.execute_reply":"2024-02-14T02:07:13.273900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# higher accuracy than a regular NN easily\n# compared to two non-cnn nets on a gpu and cpu\nimport pandas as pd\ncompare_results = pd.DataFrame([model_0_results,\n                               model_1_results,\n                               cnnModel_results])\ncompare_results[\"training_time\"] = [trainTime_model_0,\n                                    gpuTrainTime,\n                                    cnnModelTrainTime]\ncompare_results","metadata":{"id":"LutvXexu_xD8","outputId":"debe5a72-35ed-4f19-f236-dea506fec93c","execution":{"iopub.status.busy":"2024-02-14T02:07:13.276023Z","iopub.status.idle":"2024-02-14T02:07:13.276413Z","shell.execute_reply.started":"2024-02-14T02:07:13.276247Z","shell.execute_reply":"2024-02-14T02:07:13.276262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# little more visualization of the results\ncompare_results.set_index(\"model_name\")[\"model_test_acc\"].plot(kind=\"barh\")\nplt.xlabel=(\"accuracy\")\nplt.ylabel=(\"model\")","metadata":{"id":"oDuPWZBoBb_F","outputId":"b1ba3111-29b7-42e7-8651-7051c5deedf9","execution":{"iopub.status.busy":"2024-02-14T02:07:13.278402Z","iopub.status.idle":"2024-02-14T02:07:13.278742Z","shell.execute_reply.started":"2024-02-14T02:07:13.278566Z","shell.execute_reply":"2024-02-14T02:07:13.278580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizating prediction making with the CNN\ndef make_predictions(model:torch.nn.Module,\n                     data:list,\n                     device: torch.device = device):\n  prediction_probs = []\n  model.to(device)\n  model.eval()\n  with torch.inference_mode():\n    for sample in data:\n      # add a batch size dim\n      sample = torch.unsqueeze(sample, dim=0).to(device)\n      model_logit = model(sample)\n      pred_probability = torch.softmax(model_logit.squeeze(), dim=0)\n      # matplotlib only works with the cpu\n      prediction_probs.append(pred_probability.cpu())\n      # return the prob list as a tensor\n    return torch.stack(prediction_probs)\n\n","metadata":{"id":"XG-Bg7uBDdJo","execution":{"iopub.status.busy":"2024-02-14T02:07:13.279969Z","iopub.status.idle":"2024-02-14T02:07:13.280330Z","shell.execute_reply.started":"2024-02-14T02:07:13.280136Z","shell.execute_reply":"2024-02-14T02:07:13.280150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.seed(42)\ntest_samples = []\ntest_labels = []\n# get 9 random samples\nfor sample,label in random.sample(list(test_data), k=9):\n  test_samples.append(sample)\n  test_labels.append(label)\n\npred_probs = make_predictions(cnnModel, test_samples)\n# converting probs to labels\nprediction_labels = pred_probs.argmax(dim=1)\n\nplt.figure(figsize=(9,9))\nnrows = 3\nncols = 3\nfor i,sample in enumerate(test_samples):\n  # create a subplot\n  plt.subplot(nrows, ncols, i+1)\n  # # remove batch dim and plot target img\n  plt.imshow(sample.squeeze(), cmap=\"gray\")\n  # get human readable text from labels\n  pred_label = class_names[prediction_labels[i]]\n  actual_label = class_names[test_labels[i]]\n  # check equality between prediction and actual labels\n  title_text = f'Pred: {pred_label} | True: {actual_label} '\n  if pred_label == actual_label:\n    plt.title(title_text, fontsize=10, c=\"g\")\n  else:\n    plt.title(title_text, fontsize=10, c=\"r\")\n  plt.axis(False)","metadata":{"id":"HnJMtK_7Gjxd","outputId":"ef3a5fbf-9440-4260-c30b-7dbd04fc4de1","execution":{"iopub.status.busy":"2024-02-14T02:08:23.898600Z","iopub.execute_input":"2024-02-14T02:08:23.899437Z","iopub.status.idle":"2024-02-14T02:08:25.938490Z","shell.execute_reply.started":"2024-02-14T02:08:23.899403Z","shell.execute_reply":"2024-02-14T02:08:25.937556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# more prediction evaluation with a confusion matrix\npredictions = []\ncnnModel.eval()\nwith torch.inference_mode():\n  for img, label in dataLoader_Test:\n    img, label = img.to(device), label.to(device)\n    logit = cnnModel(img)\n    pred = torch.softmax(logit.squeeze(), dim=0).argmax(dim=1)\n    predictions.append(pred.cpu())\n  pred_tensor = torch.cat(predictions)\npred_tensor\n","metadata":{"id":"4HL4SByESfNw","outputId":"917e0768-9cc6-4f03-b774-beca1eecadfa","execution":{"iopub.status.busy":"2024-02-14T02:07:13.283162Z","iopub.status.idle":"2024-02-14T02:07:13.283504Z","shell.execute_reply.started":"2024-02-14T02:07:13.283350Z","shell.execute_reply":"2024-02-14T02:07:13.283363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchmetrics -U mlxtend\nimport torchmetrics, mlxtend\n\n","metadata":{"id":"kbq-4dI0lVLU","execution":{"iopub.status.busy":"2024-02-14T02:07:44.458445Z","iopub.execute_input":"2024-02-14T02:07:44.458784Z","iopub.status.idle":"2024-02-14T02:07:57.242510Z","shell.execute_reply.started":"2024-02-14T02:07:44.458759Z","shell.execute_reply":"2024-02-14T02:07:57.241293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics import ConfusionMatrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\n# setup confusion matrix instance and compare predictions to target\nconfusion_mat = ConfusionMatrix(task='multiclass',num_classes=len(class_names))\n# labels = targets\nconfmat_tensor = confusion_mat(preds=pred_tensor, target=test_data.targets).numpy()\nfigure = plot_confusion_matrix(\n    conf_mat = confmat_tensor,\n    class_names=class_names,\n    figsize=(10,7))\n","metadata":{"id":"y0k3BHA978pA","execution":{"iopub.status.busy":"2024-02-14T02:10:19.733010Z","iopub.execute_input":"2024-02-14T02:10:19.733517Z","iopub.status.idle":"2024-02-14T02:10:20.266040Z","shell.execute_reply.started":"2024-02-14T02:10:19.733484Z","shell.execute_reply":"2024-02-14T02:10:20.264794Z"},"trusted":true},"execution_count":null,"outputs":[]}]}